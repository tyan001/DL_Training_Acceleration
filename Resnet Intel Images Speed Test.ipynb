{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet decreasing training time\n",
    "\n",
    "This python code is just an experiment to speed of training time by using Tensroflow's XLA, a domain-specific compiler for linear algebra that can accelerate TensorFlow models with so source code changes. I also use mixed precision training which is a method to train models using 16-bit float number(half-precision) vs 32-bit float number(single precision). By using half-precision we use less memory and also reduce time when doing calculation. Both these two methods can bring great improvements depending on the situation. XLA can bring up to 7 times performance improvement while half-precision can bring 3 times of an improvement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import L2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import mixed_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Tensorflow-2.4.x\n",
    "try:\n",
    "    tf_gpus = tf.config.list_physical_devices('GPU')\n",
    "    for gpu in tf_gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255., rotation_range=10,width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14034 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = train_datagen.flow_from_directory('../input/intel-image-classification/seg_train/seg_train', \n",
    "                                              target_size=(128,128),\n",
    "                                              batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_gen = test_datagen.flow_from_directory('../input/intel-image-classification/seg_test/seg_test',\n",
    "                                            target_size=(128,128),\n",
    "                                            batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_gen = test_datagen.flow_from_directory('../input/intel-image-classification/seg_test/seg_test',\n",
    "                                            target_size=(128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = ResNet50(include_top=False, input_shape=(128,128,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 134, 134, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 64, 64, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 64, 64, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 64, 64, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 66, 66, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 32, 32, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 32, 32, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 32, 32, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 32, 32, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 32, 32, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 32, 32, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 32, 32, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 32, 32, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 32, 32, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 32, 32, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 32, 32, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 32, 32, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 32, 32, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 32, 32, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 32, 32, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 32, 32, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 32, 32, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 16, 16, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 16, 16, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 16, 16, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 16, 16, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 16, 16, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 16, 16, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 16, 16, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 16, 16, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 16, 16, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 16, 16, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 16, 16, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 16, 16, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 16, 16, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 16, 16, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 16, 16, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 16, 16, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 16, 16, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 16, 16, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 8, 8, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 8, 8, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 8, 8, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 8, 8, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 8, 8, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 8, 8, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 8, 8, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 8, 8, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 8, 8, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 8, 8, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 8, 8, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 8, 8, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 8, 8, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 8, 8, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 8, 8, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 8, 8, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 8, 8, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 8, 8, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 8, 8, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 8, 8, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 8, 8, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 8, 8, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 8, 8, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 8, 8, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 8, 8, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 8, 8, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 4, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 4, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 4, 4, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 4, 4, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 4, 4, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 4, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 4, 4, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 4, 4, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 4, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 4, 4, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 4, 4, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 4, 4, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_acc_callback(tf.keras.callbacks.Callback):\n",
    " \n",
    "    def on_epoch_end(self,epoch, logs={}):\n",
    "        threshold = 0.95\n",
    "        if logs.get('acc') >= threshold:  # change to 'acc' if you get NoneType and float error\n",
    "            print('\\naccuracy is greater than {}'.format(threshold))\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = my_acc_callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history, info_type='loss'):\n",
    "\n",
    "    \"\"\"\n",
    "    history: the history callback from a model.fit\n",
    "    info_type: what you want to show. (e.g. 'loss', 'acc', 'accuracy')\n",
    "    \"\"\"\n",
    "    plt.plot(history.history[info_type], label=[info_type])\n",
    "    try:\n",
    "        plt.plot(history.history['val_' + info_type], label=['val_' + info_type])\n",
    "    except Exception:\n",
    "        print(f'no val_{info_type}')\n",
    "    plt.title(info_type)\n",
    "    plt.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    tf.random.set_seed(100)\n",
    "    resnet_model = ResNet50(include_top=False, input_shape=(128,128,3))\n",
    "\n",
    "    resnet = tf.keras.Sequential([\n",
    "        resnet_model,\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(512, activation='relu', activity_regularizer=L2(0.01)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(256, activation='relu', activity_regularizer=L2(0.01)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(128, activation='relu', activity_regularizer=L2(0.01)),\n",
    "        tf.keras.layers.Dense(6, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return resnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.optimizer.get_jit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Policy \"float32\">"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_precision.global_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 4, 4, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               16777728  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 40,530,438\n",
      "Trainable params: 40,477,318\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = resnet.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(0.0001), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "220/220 [==============================] - 53s 197ms/step - loss: 3.1184 - acc: 0.1826\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 44s 193ms/step - loss: 1.7659 - acc: 0.2429\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 44s 193ms/step - loss: 1.5968 - acc: 0.3823\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 43s 192ms/step - loss: 1.3686 - acc: 0.4743\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 44s 193ms/step - loss: 1.2451 - acc: 0.4776\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 43s 192ms/step - loss: 1.1748 - acc: 0.4825\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 43s 192ms/step - loss: 1.1359 - acc: 0.4953\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 44s 193ms/step - loss: 0.9228 - acc: 0.6490\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 45s 197ms/step - loss: 0.8370 - acc: 0.6429\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 46s 203ms/step - loss: 0.7909 - acc: 0.6797\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 45s 201ms/step - loss: 0.6558 - acc: 0.7668\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 45s 200ms/step - loss: 0.5795 - acc: 0.7863\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 45s 201ms/step - loss: 0.5360 - acc: 0.7921\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 45s 200ms/step - loss: 0.5121 - acc: 0.7915\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 45s 200ms/step - loss: 0.4853 - acc: 0.8036\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 45s 197ms/step - loss: 0.4878 - acc: 0.7952\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 44s 194ms/step - loss: 0.4616 - acc: 0.8052\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 45s 197ms/step - loss: 0.4578 - acc: 0.8054\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 45s 197ms/step - loss: 0.4084 - acc: 0.8848\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 44s 194ms/step - loss: 0.3671 - acc: 0.91650s - loss: 0.3671 - acc: 0.916\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 45s 199ms/step - loss: 0.3348 - acc: 0.9302\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 44s 195ms/step - loss: 0.3442 - acc: 0.9196\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 44s 196ms/step - loss: 0.3275 - acc: 0.9284\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 45s 201ms/step - loss: 0.2966 - acc: 0.9378\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 44s 197ms/step - loss: 0.2872 - acc: 0.9379\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 44s 195ms/step - loss: 0.2716 - acc: 0.9459\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 44s 195ms/step - loss: 0.2614 - acc: 0.9440\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 46s 202ms/step - loss: 0.2553 - acc: 0.9439\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 46s 202ms/step - loss: 0.2248 - acc: 0.9568\n",
      "\n",
      "accuracy is greater than 0.95\n",
      "Wall time: 21min 39s\n"
     ]
    }
   ],
   "source": [
    "%time r = resnet.fit(train_gen, epochs=100, workers=12, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_time = (21*60) + 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no val_loss\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(r, info_type=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no val_acc\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(r, info_type=\"acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 6s 44ms/step - loss: 0.3853 - acc: 0.9003\n",
      "Test loss: 0.3853062391281128\n",
      "Test accuracy: 0.9003333449363708\n"
     ]
    }
   ],
   "source": [
    "scores = resnet.evaluate(valid_gen, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.config.optimizer.set_jit(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.optimizer.get_jit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(0.0001), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "220/220 [==============================] - 76s 181ms/step - loss: 3.1092 - acc: 0.1765\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 64s 286ms/step - loss: 1.7588 - acc: 0.2576\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 41s 181ms/step - loss: 1.5777 - acc: 0.3907\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 41s 179ms/step - loss: 1.3640 - acc: 0.4748\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 40s 176ms/step - loss: 1.2552 - acc: 0.4830\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 41s 180ms/step - loss: 1.1852 - acc: 0.4826\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 41s 181ms/step - loss: 1.1489 - acc: 0.4837\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 42s 185ms/step - loss: 1.1188 - acc: 0.4884\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 41s 179ms/step - loss: 1.0247 - acc: 0.6143\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 40s 177ms/step - loss: 0.7191 - acc: 0.7640\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 41s 183ms/step - loss: 0.6214 - acc: 0.7778\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 41s 180ms/step - loss: 0.5504 - acc: 0.7906\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 42s 183ms/step - loss: 0.5277 - acc: 0.7909\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 42s 184ms/step - loss: 0.5034 - acc: 0.8019\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 42s 184ms/step - loss: 0.4839 - acc: 0.8067\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 44s 192ms/step - loss: 0.4735 - acc: 0.7977\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 45s 197ms/step - loss: 0.4598 - acc: 0.8046\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 45s 199ms/step - loss: 0.4113 - acc: 0.8811\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 45s 197ms/step - loss: 0.3613 - acc: 0.9235\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 44s 193ms/step - loss: 0.3309 - acc: 0.9335\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 41s 183ms/step - loss: 0.3203 - acc: 0.9328\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 42s 185ms/step - loss: 0.3123 - acc: 0.9329\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 41s 182ms/step - loss: 0.3152 - acc: 0.9321\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 40s 176ms/step - loss: 0.2998 - acc: 0.9356\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 41s 182ms/step - loss: 0.2904 - acc: 0.9425\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 41s 179ms/step - loss: 0.2734 - acc: 0.9431\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 42s 183ms/step - loss: 0.2527 - acc: 0.9479\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 40s 178ms/step - loss: 0.2377 - acc: 0.9504\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 40s 177ms/step - loss: 0.2318 - acc: 0.9529\n",
      "\n",
      "accuracy is greater than 0.95\n",
      "Wall time: 21min 6s\n"
     ]
    }
   ],
   "source": [
    "%time r = resnet.fit(train_gen, epochs=100, workers=12, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "XLA_time = (21*60) + 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no val_loss\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(r, info_type=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no val_acc\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(r, info_type=\"acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 8s 33ms/step - loss: 0.3362 - acc: 0.9123\n",
      "Test loss: 0.33620011806488037\n",
      "Test accuracy: 0.9123333096504211\n"
     ]
    }
   ],
   "source": [
    "scores = resnet.evaluate(valid_gen, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixed Precision Notes\n",
    "Mixed precision training is using half-precision for all layers except the input and output layers\n",
    "\n",
    "## Increasing your batch size\n",
    "If it doesn't affect model quality, try running with double the batch size when using mixed precision. As float16 tensors use half the memory, this often allows you to **double your batch size without running out of memory**. Increasing batch size typically increases training throughput, i.e. the training elements per second your model can run on.\n",
    "\n",
    "\n",
    "## Ensuring GPU Tensor Cores are used\n",
    "As mentioned previously, modern NVIDIA GPUs use a special hardware unit called Tensor Cores that can multiply float16 matrices very quickly. However, Tensor Cores requires certain dimensions of tensors to be a multiple of 8. In the examples below, an argument is bold if and only if it needs to be a multiple of 8 for Tensor Cores to be used.\n",
    "\n",
    "tf.keras.layers.Dense(units=**64**) <br>\n",
    "tf.keras.layers.Conv2d(filters=**48**, kernel_size=7, stride=3)<br>\n",
    "And similarly for other convolutional layers, such as tf.keras.layers.Conv3d<br>\n",
    "tf.keras.layers.LSTM(units=**64**)<br>\n",
    "And similar for other RNNs, such as tf.keras.layers.GRU<br>\n",
    "tf.keras.Model.fit(epochs=2, batch_size=**128**)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14034 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = train_datagen.flow_from_directory('../input/intel-image-classification/seg_train/seg_train', \n",
    "                                              target_size=(128,128),\n",
    "                                              batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_gen = test_datagen.flow_from_directory('../input/intel-image-classification/seg_test/seg_test',\n",
    "                                            target_size=(128,128),\n",
    "                                            batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_f16():\n",
    "    tf.random.set_seed(100)\n",
    "    resnet_model = ResNet50(include_top=False, input_shape=(128,128,3))\n",
    "    resnet_model.summary()\n",
    "    resnet = tf.keras.Sequential([\n",
    "        resnet_model,\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(512, activation='relu', activity_regularizer=L2(0.01)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(256, activation='relu', activity_regularizer=L2(0.01)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(128, activation='relu', activity_regularizer=L2(0.01)),\n",
    "        tf.keras.layers.Dense(6, activation='softmax', dtype='float32')\n",
    "    ])\n",
    "    \n",
    "    return resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.config.optimizer.set_jit(False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = mixed_precision.Policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = ResNet50(include_top=False, input_shape=(128,128,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Policy \"float32\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n"
     ]
    }
   ],
   "source": [
    "for layers in resnet_model.layers:\n",
    "    print(mixed_precision.experimental.get_layer_policy(layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking ResNet model's filter is a multiple of 8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 134, 134, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 64, 64, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 64, 64, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 64, 64, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 66, 66, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 32, 32, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 32, 32, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 32, 32, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 32, 32, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 32, 32, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 32, 32, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 32, 32, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 32, 32, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 32, 32, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 32, 32, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 32, 32, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 32, 32, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 32, 32, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 32, 32, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 32, 32, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 32, 32, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 32, 32, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 16, 16, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 16, 16, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 16, 16, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 16, 16, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 16, 16, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 16, 16, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 16, 16, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 16, 16, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 16, 16, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 16, 16, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 16, 16, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 16, 16, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 16, 16, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 16, 16, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 16, 16, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 16, 16, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 16, 16, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 16, 16, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 8, 8, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 8, 8, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 8, 8, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 8, 8, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 8, 8, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 8, 8, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 8, 8, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 8, 8, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 8, 8, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 8, 8, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 8, 8, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 8, 8, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 8, 8, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 8, 8, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 8, 8, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 8, 8, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 8, 8, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 8, 8, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 8, 8, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 8, 8, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 8, 8, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 8, 8, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 8, 8, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 8, 8, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 8, 8, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 8, 8, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 4, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 4, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 4, 4, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 4, 4, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 4, 4, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 4, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 4, 4, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 4, 4, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 4, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 4, 4, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 4, 4, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 4, 4, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet = make_model_f16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 4, 4, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               16777728  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 40,530,438\n",
      "Trainable params: 40,477,318\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"mixed_float16\">\n",
      "<Policy \"float32\">\n"
     ]
    }
   ],
   "source": [
    "for layers in resnet.layers:\n",
    "    print(mixed_precision.experimental.get_layer_policy(layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = mixed_precision.LossScaleOptimizer(tf.keras.optimizers.Adam(0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(0.0001), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "110/110 [==============================] - 36s 236ms/step - loss: inf - acc: 0.1701\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 28s 234ms/step - loss: 1.7914 - acc: 0.1789\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 28s 231ms/step - loss: 1.7848 - acc: 0.2070\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 29s 237ms/step - loss: 1.7142 - acc: 0.2850\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 28s 232ms/step - loss: 1.6216 - acc: 0.3634\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 28s 231ms/step - loss: 1.3129 - acc: 0.58844s - loss: \n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 28s 231ms/step - loss: 1.0993 - acc: 0.6274\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 28s 231ms/step - loss: 0.9737 - acc: 0.6310\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 28s 244ms/step - loss: 0.8859 - acc: 0.6320\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 28s 230ms/step - loss: 0.8368 - acc: 0.6461\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 28s 233ms/step - loss: 0.7969 - acc: 0.6496\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 28s 231ms/step - loss: 0.7810 - acc: 0.6520\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 28s 229ms/step - loss: 0.7664 - acc: 0.6654\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 28s 228ms/step - loss: 0.6922 - acc: 0.7730\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 28s 232ms/step - loss: 0.6057 - acc: 0.7862\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 28s 230ms/step - loss: 0.5482 - acc: 0.8016\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 28s 233ms/step - loss: 0.5156 - acc: 0.8011\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 28s 232ms/step - loss: 0.4947 - acc: 0.8067\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 28s 232ms/step - loss: 0.4815 - acc: 0.8087\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 28s 232ms/step - loss: 0.4573 - acc: 0.8135\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 28s 234ms/step - loss: 0.4551 - acc: 0.8159\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 28s 232ms/step - loss: 0.4542 - acc: 0.8082\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 28s 231ms/step - loss: 0.4333 - acc: 0.8139\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 28s 232ms/step - loss: 0.4206 - acc: 0.8163\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 28s 234ms/step - loss: 0.4101 - acc: 0.8217\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 28s 231ms/step - loss: 0.4137 - acc: 0.8156\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 28s 233ms/step - loss: 0.4026 - acc: 0.8197\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 28s 234ms/step - loss: 0.3965 - acc: 0.8205\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 28s 230ms/step - loss: 0.3924 - acc: 0.8250\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 27s 227ms/step - loss: 0.3871 - acc: 0.8317\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 28s 232ms/step - loss: 0.3809 - acc: 0.8531\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 28s 232ms/step - loss: 0.3317 - acc: 0.9224\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 28s 230ms/step - loss: 0.2918 - acc: 0.9425\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 28s 231ms/step - loss: 0.2663 - acc: 0.9540\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 28s 232ms/step - loss: 0.2645 - acc: 0.9505\n",
      "\n",
      "accuracy is greater than 0.95\n",
      "Wall time: 16min 29s\n"
     ]
    }
   ],
   "source": [
    "%time r = resnet.fit(train_gen, epochs=100, workers=12, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_time = (16*60) + 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 4s 32ms/step - loss: 0.3470 - acc: 0.9190\n",
      "Test loss: 0.3470221757888794\n",
      "Test accuracy: 0.9190000295639038\n"
     ]
    }
   ],
   "source": [
    "scores = resnet.evaluate(valid_gen, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "run_type = ['Regular', 'XLA', 'mixed_float16']\n",
    "train_time = [reg_time,XLA_time, mixed_time]\n",
    "colors = ['b','g','r']\n",
    "for i,v in enumerate(train_time):\n",
    "    ax.bar(run_type[i],train_time[i], color=colors[i])\n",
    "    ax.text(i,train_time[i],str(train_time[i]))\n",
    "\n",
    "ax.set_xlabel(\"Training type\")\n",
    "ax.set_ylabel(\"time in seconds\")\n",
    "ax.set_title('Time taken to get to 95% training accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 1.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "xla_change =reg_time/XLA_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6% training speed decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "float16_change = reg_time/mixed_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31.34% training speed decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "percent_time = [base,xla_change, float16_change]\n",
    "colors = ['b','g','r']\n",
    "for i,v in enumerate(percent_time):\n",
    "    ax.bar(run_type[i],percent_time[i], color=colors[i])\n",
    "    ax.text(i,percent_time[i],str(np.round(percent_time[i],2)))\n",
    "ax.set_xlabel(\"Training type\")\n",
    "ax.set_ylabel(\"% faster\")\n",
    "ax.set_title('Precentage of speed compared to regular training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this small experiment we can see that XLA and mixed precision training decreases training time while keeping accuracy about the same or better. Since this is a relatively a small model we probably don't see a big difference in training time as I have done other experiments that can give XLA about a 15% training time decrease. In mixed precision training I was able to actually get a 300% time decreased (16 min vs 5 min) but that was when I was testing with random weights. But in most beginning models the starting weights are going to be random so it should be fine.\n",
    "\n",
    "In this experiment we did not see a drastic improvement most likely because of model size and hardware limitations. When checking information online it seems that XLA was tested with parallel GPU hardware on a much bigger model known as BERT.\n",
    "https://www.tensorflow.org/xla\n",
    "\n",
    "For mixed-precision training, again since its a relatively small model it is probably using more time doing other processes in training than doing calculation.\n",
    "\n",
    "Nevertheless, there are improvements when using these two methods. I have tried training with XLA and mixed precision but have so far failed to do so. More experiment will be done to explore on this training methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
